# Презентация работы

Добрый день меня зовут Кирилл Сетдеков

Это презентация финальной работы по теме Решение задачи регрессии для многокомпонентных временных рядов для детектирования режимов работы насосного оборудования.

Основная задача этой работает построить прогноз производительности нефтяного центробежных насоса с использованием лучших современных алгоритмов и сравните их качество

Я расскажу про бенчмарк, который я использовал для отбора методов и потом перейду к описанию данных и выбранных подходов.

Я использовал для выбора методов benchmark ETTH2 720. Это числовые данные температуры трансформаторов за 2 года с прогнозом на 30 дней в зависимости от7  переменных. В реальной жизни это важная задача для предсказания нагрузки на сеть и аномальных состояний, ведущих к отключениям. Справа можете увидеть какие типы модели показывают лучший результат на этом бенчмарке. Между ними общее то, что три из четырех моделей это трансформеры, а одна модель с лучшим результатом - сверточная нейросеть. Последнее время задачи машинного зрения и перевода, по мере развития отрасли привели к появлению новых идеи, которые также успешно показали себя и при переносе в область прогноза временных рядом.

В этой работе использует следующие данные и подходы: 2 месяца наблюдений за 17 насосами на нефтяном месторождении с разрешением 5 минут. Обучающая и валидационная выборка разделены по времени.

Всего я использовал 5 подходов - базовая модель AutoML и четыре подхода входящих SOTA или предшествующие им: Time fusion transformers, Time Couvolution Network, просто Трансформеры и N-beats.

На этом слайде я подробно останавливается на описании целевой переменной и признаков

Целевая переменная - это средняя скорость изменения давления на входе насоса.
Остальные переменные это физические параметры на входе измерительного устройства которые расположено на поверхности земли над скважиной. Интерес построения модели в том что можно за счёт более дешевых измерительных приборов на поверхности моделей оценить параметры связанные с ухудшением производительности насоса на глубине вместо использования более дорогих датчиков.
Справа видим примеры признаков, их можно разделить на 2 группы - средняя скорость изменения (загрузки, давления и тока в разрезе по часу, дню и неделе) и вторая группа - мгновенные параметры (время работы, давление на выходе, коэффициент мощности, ток, загрузка двигателя)

О проблемах, с чем я столкнулся и как их решал в работе.

1. Первое - мало данных и долго перебирать гиперпараметры - TFT в итоге переобучилась
2. Само обучение занимало до 20 часов даже на самых мощных картах в Colab и не удалось легко перебирать гиперпараметры
3. Удалось подобрать оптимальную для TFT модели скорость обучения, но этого было не достаточно.
4. Много сил заняло написание загрузчиков данных и предобработка.
5. Подбор окна для моделей удалось решить с помощью анализа частных автокорреляции

Далее мы видим сравнение метрик моделей на валидационной выборке, которая была позже по времени чем обучающая. Модель, которая показала себя лучше всего по по всем метрикам была TCN, а худшая по $R^2$ и MAE была модель N-Beats. 
В свою очередь, Time Fusion Transformers показала результат хуже, чем AutoML на бустингах, по 2 метрикам из 3.

На этом слайде мы видим для двух разных насосов из выборки по валидации сравнение всех четырех моделей с фактом, то что TCN и Трансформеры ближе всего к истине. Это соответствует картине с прошлого слайда по сравнению итоговых метрик.

На этом слайде можем увидеть распределения остатков моделей на валидации. Для всех моделей самым сложным для предсказания был регион константных значений или единиц на этих графиках.

На этом слайде и следующем приведена дополнительная визуализация для внимания, которое содержится в TFT. Хотя модель показал себя не очень хорошо по метрикам, мы можем лучше ее энетпретировать. Слева мы видим какая активация этой модели в части временного домена. По сути, как далеко и на что смотрит модель делая прогноз - на локальную информацию и пик около -150 - как раз на поведение при прошлом включении.

Справа приведены выводы значимости признаков для энкодера - мы видим что время простоя насоса было наиболее значимо.

На следующим слайде - аналогично справа для декодера наиболее значимой переменной был коэффициент мощности. Слева - анализ значимости для статических переменных. У нас статичной переменной был идентификатор насоса - по сути выделены насосы которые ведут себя необычнее других.

Переходя к результатам:

1. для  3 из четырех модели удалось показать качество лучше чем AutoML
2. У TFT модели в моей работе на этих данных была тенденция к переобучению - это дальнейший план сжимать число параметром, упрощать модель и сильнее регуляризовать, она должна работать не хуже трансформеров классических
3. Для моделей трансформеров рассмотрение attention позволяет гибче анализировать и интерпретировать их работу

Дополнительно в качестве иллюстраций, можно посмотреть пример сравнения  факта и прогноза для каждой из четырех моделей где чёрная линия это реальное значение и синее - прогноз.
TCN
Трансформер
Н-Битс
Тайм фьюжн трансформер
