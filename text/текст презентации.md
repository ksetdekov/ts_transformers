# Презентация работы

Добрый день меня зовут Кирилл Сетдеков

Это презентация финальной работы по теме Решение задачи регрессии для многокомпонентных временных рядов для детектирования режимов работы насосного оборудования.

Основная задача этой работает построить прогноз производительности нефтяного центробежных насоса с использованием лучших современных алгоритмов и сравнить их качество между собой.

Я расскажу про бенчмарк, который я использовал для отбора методов и потом перейду к описанию данных и выбранных подходов.

Я использовал для выбора методов benchmark ETTH2 720. Это числовые данные температуры трансформаторов за 2 года с прогнозом на 30 дней в зависимости от 7  переменных. В реальной жизни это важная задача для предсказания нагрузки на сеть и аномальных состояний, ведущих к отключениям. Справа можете увидеть какие типы модели показывают лучший результат на этом бенчмарке. Между ними общее то, что три из четырех моделей это трансформеры, а одна модель с лучшим результатом - сверточная нейросеть. Последнее время задачи машинного зрения и перевода, по мере развития отрасли привели к появлению новых идеи, которые также успешно показали себя и при переносе в область прогноза временных рядов.

В этой работе использует следующие данные и подходы: 2 месяца наблюдений за 17 насосами на нефтяном месторождении с разрешением 5 минут. Обучающая и валидационная выборка разделены по времени.

Всего я использовал 5 подходов - базовая модель AutoML и четыре подхода входящих в SOTA или предшествующие им: Time fusion transformers, Time Convolution Network, просто Трансформеры и N-beats.

На этом слайде я подробно останавливается на описании целевой переменной и признаков

Целевая переменная - это средняя скорость изменения давления на входе насоса.
Остальные переменные это физические параметры на входе измерительного устройства которое расположено на поверхности земли над скважиной. Интерес построения модели в том что можно за счёт более дешевых измерительных приборов на поверхности и модели машинного обучения оценить параметры связанные с ухудшением производительности насоса на глубине, вместо использования более дорогих датчиков.
Справа видим примеры признаков, их можно разделить на 2 группы - средняя скорость изменения (загрузка, давление и ток в разрезе по часу, дню и неделе) и вторая группа - мгновенные параметры (время работы, давление на выходе, коэффициент мощности, ток, загрузка двигателя)

О проблемах, с чем я столкнулся и как их решал в работе.

1. Первое - мало данных и долго перебирать гиперпараметры - модель TFT в итоге переобучилась.
2. Само обучение занимало до 20 часов даже на самых мощных картах в Colab и не удалось легко перебирать гиперпараметры.
3. Удалось подобрать оптимальную для модели TFT скорость обучения, но этого было не достаточно.
4. Много сил заняла предобработка и написание загрузчиков данных.
5. Задачу подбора окна для моделей удалось решить с помощью анализа частных автокорреляции

Далее мы видим сравнение метрик моделей на валидационной выборке, которая была позже по времени чем обучающая. Модель, которая показала себя лучше всего по всем метрикам была TCN, а худшая по $R^2$ и MAE была модель N-Beats. 
В свою очередь, Time Fusion Transformers показала результат хуже, чем AutoML на бустингах, по 2 метрикам из 3.

На этом слайде мы видим для двух разных насосов из выборки по валидации сравнение всех четырех моделей с фактом, и то что TCN и Трансформеры ближе всего к истине. Это соответствует картине с прошлого слайда по сравнению итоговых метрик.

На этом слайде можем увидеть распределения остатков моделей на валидации. Для всех моделей самым сложным для предсказания был регион константных значений или единиц на этих графиках.

На этом слайде и следующем приведена дополнительная визуализация для механизма внимания, который содержится в TFT. Хотя модель показал себя не очень хорошо по метрикам, мы можем лучше ее интерпретировать. Слева мы видим среднюю активацию этой модели во временном домене. По сути, как далеко и на что смотрит модель делая прогноз - на локальную информацию и пик около -150 - как раз на поведение при прошлом включении насоса.

Справа приведены значимости признаков для энкодера - мы видим что время простоя насоса было наиболее значимо.

На следующим слайде - аналогично справа для декодера наиболее значимой переменной был коэффициент мощности. Слева - анализ значимости для статических переменных. У нас статичной переменной был идентификатор насоса - по сути выделены насосы которые ведут себя необычнее других.

Переходя к результатам:

1. Для  трех из четырех модели удалось показать качество лучше чем AutoML.
2. У TFT модели в моей работе на этих данных была тенденция к переобучению - это возможный план дальнейшей работы - сжимать число параметрв, упрощать модель и сильнее регуляризовать, она по идее должна работать не хуже классических трансформеров.
3. Для моделей трансформеров рассмотрение attention позволяет гибче анализировать и интерпретировать их работу.

Дополнительно в качестве иллюстраций, можно посмотреть пример сравнения  факта и прогноза для каждой из четырех моделей где чёрная линия это реальное значение и синее - прогноз.
Мы видим графики для
TCN
Трансформера
Н-Битс
Тайм фьюжн трансформера
